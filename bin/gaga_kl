#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import click
import gaga
import phsp
import torch
import numpy as np
from torch.autograd import Variable
import torch.nn.functional as F
from matplotlib import pyplot as plt
from scipy.stats import entropy

CONTEXT_SETTINGS = dict(help_option_names=['-h', '--help'])
@click.command(context_settings=CONTEXT_SETTINGS)
@click.argument('phsp_filename')
@click.argument('pth_filename')
@click.option('--n', '-n',
              default=1e4,
              help='Number of samples to generate')
@click.option('--nb_bins', '-b',
              default=int(200),
              help='Number of bins')
def gaga_kl(phsp_filename, pth_filename, n, nb_bins):
    '''
    \b
    Compute KL between real and GAN generated distributions

    \b
    <PHSP_FILENAME>   : input phase space file PHSP file (.npy)
    <PTH_FILENAME>    : input GAN PTH file (.pth)
    '''

    n = int(n)

    # load phsp
    real, keys, m = phsp.load(phsp_filename, n)

    # load pth
    params, G, optim, dtypef= gaga.load(pth_filename)
    
    # generate samples
    fake = gaga.generate_samples2(params, G, n,
                                  batch_size=1e5, un_norm=True, to_numpy=True)
    
    x_dim = params['x_dim']
    for i in range(x_dim):
        x = real[:,i]
        y = fake[:,i]
        jsd = gaga.Jensen_Shannon_divergence(x, y, nb_bins)
        print(' {} {:3.6f}'.format(keys[i], jsd))


    

# --------------------------------------------------------------------------
if __name__ == '__main__':
    gaga_kl()

